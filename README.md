# Metis_Project_5

This repository contains work for my passion project, DeepLew, a modern chess engine and homage to IBM's Deep Blue. Our workflow is fairly straightforward: we follow the general history of chess engines starting with minimax algorithms at variable depth and eventually incorporating neural networks for a more modern approach. A simple walkthrough of making moves and some simulated minimax games is shown in *chess_walkthrough.ipynb*.

In py_files, you can find all sorts of functions that provide the workhorse functions for both iterations of this project. Most importantly, in *chess_workhorse_tools.py* there are functions that gather possible moves, designate point values to moves given a current board start. There are also functions that facilitate the design of our convolutional neural network that encode the board, moves, and interpret the actions the cnn predicts. In the *dynamic_depth.py* file, there are functions that use recursion to calculate the branches of possible moves given a board. These are the tools for the minimax algorithm.

The design and implementation of the convolutional neural network can be found in *cnn_training_and_model*. Major shoutout to Victor Sim for his dataset of chess games that was properly filtered and reduced to chess players with serious resumes. The network was designed using encoded board stated with a target of moves seasoned chess players would make. A head up to anybody who wants to follow the workflow on their own: just 20,000 games turns into about 1.2 million boards which will take many hours to train the CNN locally. The CNN ultimately became a method to understand how we could begin the process of deep learning when creating a chess engine and its predictions must be taken with a grain of salt. Ultimately, to make something more robust reinforcement methods must be used.